import cv2
import os
import threading
import time
import numpy as np
import winsound
import requests
import shutil
import mysql.connector
from datetime import datetime
from ultralytics import YOLO
from deepface import DeepFace

# === C·∫§U H√åNH T·ª™ FILE C≈® ===
BASE_URL = "https://khai-security-robot-f5870f032456.herokuapp.com"
GET_FAMILY_LIST_API = f"{BASE_URL}/get_family_list"
GET_FAMILY_IMG_API = f"{BASE_URL}/get_family_image"

DB_CONFIG = {
    'host': 'lmag6s0zwmcswp5w.cbetxkdyhwsb.us-east-1.rds.amazonaws.com',
    'user': 'iocpivuiapovtydo',
    'password': 'blqxnptzoye9snv2',
    'database': 'swb77e48ogfk0kvv',
    'port': 3306
}

THU_MUC_BAO_DONG = "security_alerts"
THU_MUC_DATA_LOCAL = "local_family_data"
MODEL_NAME = "Facenet512"
DETECTOR_BACKEND = "ssd"
NGUONG_NHAN_DIEN = 0.8
DANGER_ZONE = [100, 100, 600, 500]
DELAY_BAO_DONG = 10.0

class SecuritySystem:
    def __init__(self):
        self.is_running = False
        self.shared_frame = None
        self.lock = threading.Lock()
        self.verified_tracks = {}
        self.shared_faces = []
        self.local_db = {}
        self.last_alert_time = 0
        self.model_yolo = None
        
        # T·∫°o th∆∞ m·ª•c
        if not os.path.exists(THU_MUC_BAO_DONG): os.makedirs(THU_MUC_BAO_DONG)
        if not os.path.exists(THU_MUC_DATA_LOCAL): os.makedirs(THU_MUC_DATA_LOCAL)

    def load_resources(self):
        """H√†m n√†y ch·∫°y ng·∫ßm ƒë·ªÉ load Model AI"""
        print("--- [MODEL] ƒêang t·∫£i t√†i nguy√™n AI... ---")
        try:
            # 1. Load DeepFace
            DeepFace.build_model(MODEL_NAME)
            print("--- [MODEL] DeepFace ƒë√£ s·∫µn s√†ng.")

            # 2. ƒê·ªìng b·ªô d·ªØ li·ªáu
            self.local_db = self.sync_data_from_server()

            # 3. Load YOLO Pose
            self.model_yolo = YOLO('yolov8n-pose.pt')
            print("--- [MODEL] YOLO Pose ƒë√£ s·∫µn s√†ng.")

        except Exception as e:
            print(f"‚ùå [MODEL] L·ªói load resources: {e}")

    def sync_data_from_server(self):
        print("--- ‚¨áÔ∏è [DATA] ƒêang ƒë·ªìng b·ªô d·ªØ li·ªáu server... ---")
        local_database = {}
        server_filenames = []
        try:
            resp = requests.get(GET_FAMILY_LIST_API, timeout=10)
            if resp.status_code == 200:
                family_list = resp.json()
                for person in family_list:
                    name = person['name']
                    img_filename = person['image_path']
                    server_filenames.append(img_filename)
                    local_img_path = os.path.join(THU_MUC_DATA_LOCAL, img_filename)
                    
                    # T·∫£i ·∫£nh n·∫øu ch∆∞a c√≥
                    if not os.path.exists(local_img_path):
                        try:
                            img_resp = requests.get(f"{GET_FAMILY_IMG_API}/{img_filename}", stream=True, timeout=5)
                            if img_resp.status_code == 200:
                                with open(local_img_path, 'wb') as f:
                                    img_resp.raw.decode_content = True
                                    shutil.copyfileobj(img_resp.raw, f)
                        except: continue
                    
                    # T·∫°o Embedding
                    try:
                        embedding_objs = DeepFace.represent(img_path=local_img_path, model_name=MODEL_NAME, enforce_detection=False)
                        embedding = embedding_objs[0]["embedding"]
                        
                        # X·ª≠ l√Ω tr√πng t√™n
                        final_name = name
                        count = 1
                        while final_name in local_database:
                            final_name = f"{name}_{count}"
                            count += 1
                        local_database[final_name] = embedding
                    except: pass
            print(f"‚úÖ [DATA] ƒê√£ h·ªçc {len(local_database)} khu√¥n m·∫∑t.")
            return local_database
        except Exception as e:
            print(f"‚ùå [DATA] L·ªói ƒë·ªìng b·ªô: {e}")
            return {}

    def start_camera_thread(self):
        if not self.is_running:
            self.is_running = True
            threading.Thread(target=self.face_recognition_loop, daemon=True).start()
            threading.Thread(target=self.camera_loop, daemon=True).start()

    def stop(self):
        self.is_running = False

    def face_recognition_loop(self):
        """Lu·ªìng x·ª≠ l√Ω nh·∫≠n di·ªán khu√¥n m·∫∑t (Ch·∫°y song song)"""
        while self.is_running:
            if self.shared_frame is None:
                time.sleep(0.1)
                continue
            
            with self.lock:
                process_frame = self.shared_frame.copy()

            try:
                face_objs = DeepFace.extract_faces(img_path=process_frame, detector_backend=DETECTOR_BACKEND, enforce_detection=False, align=True)
                temp_faces = []
                for face in face_objs:
                    if face['confidence'] > 0.5:
                        # So kh·ªõp v·ªõi database
                        target_emb = DeepFace.represent(img_path=process_frame, model_name=MODEL_NAME, detector_backend=DETECTOR_BACKEND, enforce_detection=False, align=True)[0]["embedding"]
                        best_match = "Unknown"
                        min_dist = 100
                        
                        for name, db_emb in self.local_db.items():
                            dist = 1 - (np.dot(target_emb, db_emb) / (np.linalg.norm(target_emb) * np.linalg.norm(db_emb)))
                            if dist < min_dist:
                                min_dist = dist
                                best_match = name
                        
                        display_name = best_match.split('_')[0] if best_match != "Unknown" else "Unknown"
                        final_name = display_name if min_dist < NGUONG_NHAN_DIEN else "Unknown"
                        
                        temp_faces.append({
                            "name": final_name,
                            "box": [face['facial_area']['x'], face['facial_area']['y'], face['facial_area']['w'], face['facial_area']['h']]
                        })
                self.shared_faces = temp_faces
            except: pass
            time.sleep(0.1)

    def camera_loop(self):
        """V√≤ng l·∫∑p Camera ch√≠nh"""
        print("--- [CAMERA] ƒêang m·ªü Camera Imou... ---")
        
        # --- C·∫§U H√åNH CAMERA ---
        imou_pass = "KHAi2692004" 
        
        # ==> H√ÉY TH·ª¨ ƒê·ªîI IP N·∫æU .228 KH√îNG ƒê∆Ø·ª¢C
        imou_ip = "192.168.1.222" # N·∫øu l·ªói, h√£y th·ª≠ ƒë·ªïi th√†nh "192.168.1.108"
        
        rtsp_url = f"rtsp://admin:{imou_pass}@{imou_ip}:554/cam/realmonitor?channel=1&subtype=1"

        # C·∫•u h√¨nh FFMPEG ƒë·ªÉ ∆∞u ti√™n TCP v√† gi·∫£m th·ªùi gian timeout ch·ªù ƒë·ª£i
        os.environ["OPENCV_FFMPEG_CAPTURE_OPTIONS"] = "rtsp_transport;tcp|timeout;5000000" 
        
        cap = cv2.VideoCapture(rtsp_url, cv2.CAP_FFMPEG)
        # Gi·ªõi h·∫°n b·ªô ƒë·ªám ƒë·ªÉ gi·∫£m ƒë·ªô tr·ªÖ (latency)
        cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
        
        # Ki·ªÉm tra ngay l·∫≠p t·ª©c xem c√≥ m·ªü ƒë∆∞·ª£c kh√¥ng
        if not cap.isOpened():
            print(f"‚ùå L·ªñI NGHI√äM TR·ªåNG: Kh√¥ng th·ªÉ m·ªü RTSP URL: {rtsp_url}")
            print("üëâ G·ª£i √Ω: Ki·ªÉm tra l·∫°i IP (c√≥ th·ªÉ l√† .108?) ho·∫∑c t·∫Øt 'M√£ h√≥a h√¨nh ·∫£nh' tr√™n App.")
        else:
            print("‚úÖ ƒê√£ k·∫øt n·ªëi th√†nh c√¥ng v·ªõi Camera!")

        # ... (Ph·∫ßn code while loop b√™n d∆∞·ªõi gi·ªØ nguy√™n)
        # ---------------------------------------------

        # Ch·ªù load model xong n·∫øu ch∆∞a xong
        while self.model_yolo is None and self.is_running:
            print("ƒêang ch·ªù Model YOLO...")
            time.sleep(1)

        while self.is_running:
            success, img = cap.read()
            if not success: 
                print("‚ùå M·∫•t k·∫øt n·ªëi Camera! ƒêang th·ª≠ k·∫øt n·ªëi l·∫°i...")
                time.sleep(2)
                cap = cv2.VideoCapture(rtsp_url) # Th·ª≠ k·∫øt n·ªëi l·∫°i
                continue
            
            # ... (Ph·∫ßn code x·ª≠ l√Ω b√™n d∆∞·ªõi gi·ªØ nguy√™n) ...
            
            # --- YOLO TRACKING ---
            results = self.model_yolo.track(img, persist=True, verbose=False, classes=[0])
            
            if results and results[0].boxes:
                keypoints_all = results[0].keypoints.data.cpu().numpy() if results[0].keypoints else []
                
                for i, box in enumerate(results[0].boxes):
                    track_id = int(box.id[0]) if box.id is not None else -1
                    x1, y1, x2, y2 = map(int, box.xyxy[0])
                    center = (int((x1+x2)/2), int((y1+y2)/2))
                    
                    # 1. X√°c ƒë·ªãnh danh t√≠nh
                    person_name = self.verified_tracks.get(track_id, "Dang xac minh...")
                    if track_id not in self.verified_tracks:
                        for face in self.shared_faces:
                            if self.check_overlap([x1, y1, x2, y2], face['box']):
                                person_name = face['name']
                                self.verified_tracks[track_id] = person_name
                                break
                    
                    is_family = (person_name != "Unknown" and person_name != "Dang xac minh...")

                    # 2. Ph√¢n t√≠ch h√†nh vi (Pose)
                    kpts = keypoints_all[i] if len(keypoints_all) > i else None
                    action_text, action_color = self.analyze_pose_action(kpts, [x1, y1, x2, y2])

                    # 3. Logic C·∫£nh b√°o
                    in_zone = self.check_danger_zone(center, DANGER_ZONE)
                    box_color = (0, 255, 0) # Xanh
                    info_text = f"ID:{track_id} | {person_name}"

                    if in_zone:
                        if is_family:
                            box_color = (255, 255, 0) # V√†ng
                        else:
                            box_color = (0, 0, 255) # ƒê·ªè
                            info_text = f"WARNING! {person_name}"
                            
                            if action_text == "FALL DETECTED!" or person_name == "Unknown":
                                # Ph√°t ti·∫øng k√™u (Ch·∫°y lu·ªìng ri√™ng ƒë·ªÉ ko lag)
                                threading.Thread(target=winsound.Beep, args=(2000, 200)).start()
                                
                                # G·ª≠i c·∫£nh b√°o (10s/l·∫ßn)
                                if time.time() - self.last_alert_time > DELAY_BAO_DONG:
                                    self.trigger_alert(img)

                    # 4. V·∫Ω l√™n h√¨nh
                    cv2.rectangle(img, (x1, y1), (x2, y2), box_color, 2)
                    cv2.putText(img, info_text, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, box_color, 2)
                    if action_text != "Normal":
                        cv2.putText(img, action_text, (x1, y1-35), cv2.FONT_HERSHEY_SIMPLEX, 0.8, action_color, 3)
                    
                    if kpts is not None:
                        self.draw_skeleton(img, kpts)

            # V·∫Ω v√πng nguy hi·ªÉm
            cv2.rectangle(img, (DANGER_ZONE[0], DANGER_ZONE[1]), (DANGER_ZONE[2], DANGER_ZONE[3]), (0, 165, 255), 2)
            cv2.putText(img, "DANGER ZONE", (DANGER_ZONE[0], DANGER_ZONE[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 165, 255), 2)

            # C·∫≠p nh·∫≠t frame cho View
            with self.lock:
                self.shared_frame = img.copy()
            
            time.sleep(0.01)

        cap.release()

    # --- C√ÅC H√ÄM B·ªî TR·ª¢ (HELPER) T·ª™ FILE C≈® ---
    def trigger_alert(self, img):
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        fname = f"alert_{timestamp}.jpg"
        full_path = os.path.join(THU_MUC_BAO_DONG, fname)
        cv2.imwrite(full_path, img)
        self.last_alert_time = time.time()
        threading.Thread(target=self.push_alert_to_cloud, args=(1, fname)).start()
        print(f"üö® ƒê√É GHI NH·∫¨N C·∫¢NH B√ÅO: {fname}")

    def push_alert_to_cloud(self, count, fname):
        try:
            conn = mysql.connector.connect(**DB_CONFIG)
            cursor = conn.cursor()
            sql = "INSERT INTO intrusion_logs (count_people, image_path) VALUES (%s, %s)"
            cursor.execute(sql, (count, fname))
            conn.commit()
            cursor.close()
            conn.close()
        except Exception as e:
            print(f"L·ªói Cloud: {e}")

    def check_overlap(self, box_body, box_face):
        fx, fy, fw, fh = box_face
        xA = max(box_body[0], fx)
        yA = max(box_body[1], fy)
        xB = min(box_body[2], fx + fw)
        yB = min(box_body[3], fy + fh)
        return (max(0, xB - xA) * max(0, yB - yA)) > 0

    def check_danger_zone(self, center, zone):
        cx, cy = center
        return zone[0] < cx < zone[2] and zone[1] < cy < zone[3]

    def analyze_pose_action(self, keypoints, box):
        # ... (Copy y nguy√™n logic t·ª´ file c≈©) ...
        action = "Normal"
        color = (0, 255, 0)
        if keypoints is None or len(keypoints) == 0: return action, color
        
        l_shoulder = keypoints[5][:2]
        l_hip = keypoints[11][:2]
        
        x1, y1, x2, y2 = box
        w = x2 - x1
        h = y2 - y1
        
        # Ng√£
        if w > h * 1.2: 
            return "FALL DETECTED!", (0, 0, 255)
        if l_shoulder[1] > 0 and l_hip[1] > 0 and abs(l_shoulder[1] - l_hip[1]) < h * 0.1:
             return "FALL DETECTED!", (0, 0, 255)

        # Gi∆° tay (Hands Up)
        l_wrist = keypoints[9][:2]
        r_wrist = keypoints[10][:2]
        r_shoulder = keypoints[6][:2]
        
        if (l_wrist[1] > 0 and l_wrist[1] < l_shoulder[1]) or (r_wrist[1] > 0 and r_wrist[1] < r_shoulder[1]):
             return "HANDS UP", (0, 165, 255)
             
        return action, color

    def draw_skeleton(self, img, keypoints):
        # ... (Copy y nguy√™n logic v·∫Ω x∆∞∆°ng) ...
        connections = [(5, 7), (7, 9), (6, 8), (8, 10), (5, 6), (5, 11), (6, 12), (11, 12), (11, 13), (13, 15), (12, 14), (14, 16)]
        for pt1, pt2 in connections:
            if keypoints[pt1][2] > 0.5 and keypoints[pt2][2] > 0.5:
                cv2.line(img, (int(keypoints[pt1][0]), int(keypoints[pt1][1])), (int(keypoints[pt2][0]), int(keypoints[pt2][1])), (255, 0, 255), 2)

    def get_frame(self):
        with self.lock:
            if self.shared_frame is not None:
                return self.shared_frame.copy()
        return None
    
    def get_alert_stats(self):
        today_str = datetime.now().strftime("%Y%m%d")
        all_files = [os.path.join(THU_MUC_BAO_DONG, f) for f in os.listdir(THU_MUC_BAO_DONG) if f.endswith(".jpg")]
        todays = [f for f in all_files if today_str in f]
        todays.sort(key=os.path.getmtime, reverse=True) # M·ªõi nh·∫•t l√™n ƒë·∫ßu
        return len(todays), todays
    
    # Trong file models/security_logic.py

    def upload_new_member(self, name, frame):
        """L∆∞u ·∫£nh t·∫°m v√† g·ª≠i l√™n server ƒë·ªÉ ƒëƒÉng k√Ω ng∆∞·ªùi nh√†"""
        try:
            img_path = "temp_register.jpg"
            cv2.imwrite(img_path, frame)
            
            with open(img_path, "rb") as f:
                # S·ª≠ d·ª•ng UPLOAD_URL ƒë√£ ƒë·ªãnh nghƒ©a ·ªü ƒë·∫ßu file
                response = requests.post(f"{BASE_URL}/add_member", 
                                         data={"name": name}, 
                                         files={"image": f}, 
                                         timeout=15)
            return response.json()
        except Exception as e:
            return {"status": "error", "message": str(e)}

    def fetch_server_logs(self):
        """L·∫•y danh s√°ch log x√¢m nh·∫≠p t·ª´ server Heroku"""
        try:
            response = requests.get(f"{BASE_URL}/get_logs", timeout=10)
            if response.status_code == 200:
                return response.json()
            return []
        except:
            return []