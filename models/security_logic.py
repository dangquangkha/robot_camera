import cv2
import os
import threading
import time
import numpy as np
import winsound
import requests
import shutil
import mysql.connector
from datetime import datetime
from ultralytics import YOLO
from deepface import DeepFace
import re
# === C·∫§U H√åNH T·ª™ FILE C≈® ===
BASE_URL = "https://khai-security-robot-f5870f032456.herokuapp.com"
GET_FAMILY_LIST_API = f"{BASE_URL}/get_family_list"
GET_FAMILY_IMG_API = f"{BASE_URL}/get_family_image"

DB_CONFIG = {
    'host': 'lmag6s0zwmcswp5w.cbetxkdyhwsb.us-east-1.rds.amazonaws.com',
    'user': 'iocpivuiapovtydo',
    'password': 'blqxnptzoye9snv2',
    'database': 'swb77e48ogfk0kvv',
    'port': 3306
}

THU_MUC_BAO_DONG = "security_alerts"
THU_MUC_DATA_LOCAL = "local_family_data"
MODEL_NAME = "Facenet512"
DETECTOR_BACKEND = "ssd"
NGUONG_NHAN_DIEN = 0.8
DANGER_ZONE = [100, 100, 600, 500]
DELAY_BAO_DONG = 10.0

class SecuritySystem:
    def __init__(self):
        self.is_running = False
        self.shared_frame = None
        self.lock = threading.Lock()
        self.verified_tracks = {}
        self.shared_faces = []
        self.local_db = {}
        self.last_alert_time = 0
        self.model_yolo = None
        
        # T·∫°o th∆∞ m·ª•c
        if not os.path.exists(THU_MUC_BAO_DONG): os.makedirs(THU_MUC_BAO_DONG)
        if not os.path.exists(THU_MUC_DATA_LOCAL): os.makedirs(THU_MUC_DATA_LOCAL)

        self.current_camera_index = 0
        self.camera_configs = {
            # ƒê·ªïi d·∫•u "-" th√†nh ":" ƒë·ªÉ chu·∫©n h√≥a
            "CAM_01": {"mac": "1c:4d:89:d8:c0:FB", "ip": "192.168.0.3", "user": "admin", "pass": "L2D1833A"}, 
            "CAM_02": {"mac": "1c:4d:89:d8:c5:be", "ip": "192.168.1.222", "user": "admin", "pass": "L2D1833A"}
        }
        self.camera_urls = [
        "rtsp://admin:L2D1833A@192.168.0.3:554/cam/realmonitor?channel=1&subtype=1",
        "rtsp://admin:L2D1833A@192.168.1.222:554/cam/realmonitor?channel=1&subtype=1" # Camera th·ª© 2
        ]
        self.cap = None

    def load_resources(self):
        """H√†m n√†y ch·∫°y ng·∫ßm ƒë·ªÉ load Model AI"""
        print("--- [MODEL] ƒêang t·∫£i t√†i nguy√™n AI... ---")
        try:
            # 1. Load DeepFace
            DeepFace.build_model(MODEL_NAME)
            print("--- [MODEL] DeepFace ƒë√£ s·∫µn s√†ng.")

            # 2. ƒê·ªìng b·ªô d·ªØ li·ªáu
            self.local_db = self.sync_data_from_server()

            # 3. Load YOLO Pose
            self.model_yolo = YOLO('yolov8n-pose.pt')
            print("--- [MODEL] YOLO Pose ƒë√£ s·∫µn s√†ng.")

        except Exception as e:
            print(f"‚ùå [MODEL] L·ªói load resources: {e}")

    def sync_data_from_server(self):
        print("--- ‚¨áÔ∏è [DATA] ƒêang ƒë·ªìng b·ªô d·ªØ li·ªáu server... ---")
        local_database = {}
        server_filenames = []
        try:
            resp = requests.get(GET_FAMILY_LIST_API, timeout=10)
            if resp.status_code == 200:
                family_list = resp.json()
                for person in family_list:
                    name = person['name']
                    img_filename = person['image_path']
                    server_filenames.append(img_filename)
                    local_img_path = os.path.join(THU_MUC_DATA_LOCAL, img_filename)
                    
                    # T·∫£i ·∫£nh n·∫øu ch∆∞a c√≥
                    if not os.path.exists(local_img_path):
                        try:
                            img_resp = requests.get(f"{GET_FAMILY_IMG_API}/{img_filename}", stream=True, timeout=5)
                            if img_resp.status_code == 200:
                                with open(local_img_path, 'wb') as f:
                                    img_resp.raw.decode_content = True
                                    shutil.copyfileobj(img_resp.raw, f)
                        except: continue
                    
                    # T·∫°o Embedding
                    try:
                        embedding_objs = DeepFace.represent(img_path=local_img_path, model_name=MODEL_NAME, enforce_detection=False)
                        embedding = embedding_objs[0]["embedding"]
                        
                        # X·ª≠ l√Ω tr√πng t√™n
                        final_name = name
                        count = 1
                        while final_name in local_database:
                            final_name = f"{name}_{count}"
                            count += 1
                        local_database[final_name] = embedding
                    except: pass
            print(f"‚úÖ [DATA] ƒê√£ h·ªçc {len(local_database)} khu√¥n m·∫∑t.")
            return local_database
        except Exception as e:
            print(f"‚ùå [DATA] L·ªói ƒë·ªìng b·ªô: {e}")
            return {}

    def start_camera_thread(self):
        if not self.is_running:
            self.is_running = True
            threading.Thread(target=self.face_recognition_loop, daemon=True).start()
            threading.Thread(target=self.camera_loop, daemon=True).start()

    def stop(self):
        self.is_running = False

    def face_recognition_loop(self):
        """Lu·ªìng x·ª≠ l√Ω nh·∫≠n di·ªán khu√¥n m·∫∑t (Ch·∫°y song song)"""
        while self.is_running:
            if self.shared_frame is None:
                time.sleep(0.1)
                continue
            
            with self.lock:
                process_frame = self.shared_frame.copy()

            try:
                face_objs = DeepFace.extract_faces(img_path=process_frame, detector_backend=DETECTOR_BACKEND, enforce_detection=False, align=True)
                temp_faces = []
                for face in face_objs:
                    if face['confidence'] > 0.5:
                        # So kh·ªõp v·ªõi database
                        target_emb = DeepFace.represent(img_path=process_frame, model_name=MODEL_NAME, detector_backend=DETECTOR_BACKEND, enforce_detection=False, align=True)[0]["embedding"]
                        best_match = "Unknown"
                        min_dist = 100
                        
                        for name, db_emb in self.local_db.items():
                            dist = 1 - (np.dot(target_emb, db_emb) / (np.linalg.norm(target_emb) * np.linalg.norm(db_emb)))
                            if dist < min_dist:
                                min_dist = dist
                                best_match = name
                        
                        display_name = best_match.split('_')[0] if best_match != "Unknown" else "Unknown"
                        final_name = display_name if min_dist < NGUONG_NHAN_DIEN else "Unknown"
                        
                        temp_faces.append({
                            "name": final_name,
                            "box": [face['facial_area']['x'], face['facial_area']['y'], face['facial_area']['w'], face['facial_area']['h']]
                        })
                self.shared_faces = temp_faces
            except: pass
            time.sleep(0.1)

    def switch_camera(self):
        """H√†m n√†y s·∫Ω ƒë∆∞·ª£c g·ªçi khi b·∫•m n√∫t tr√™n giao di·ªán"""
        self.current_camera_index = (self.current_camera_index + 1) % len(self.camera_urls)
        print(f"--- ƒêang chuy·ªÉn sang Camera: {self.current_camera_index} ---")
        
        # Gi·∫£i ph√≥ng camera hi·ªán t·∫°i ƒë·ªÉ loop nh·∫≠n di·ªán ra success = False v√† t·ª± k·∫øt n·ªëi l·∫°i
        if self.cap is not None:
            self.cap.release()
    
    def update_ips_by_mac(self):
        """Qu√©t m·∫°ng ƒë·ªÉ t√¨m IP m·ªõi nh·∫•t d·ª±a tr√™n ƒë·ªãa ch·ªâ MAC ƒë√£ bi·∫øt"""
        print("--- üîç ƒêang qu√©t m·∫°ng ƒë·ªÉ c·∫≠p nh·∫≠t IP theo MAC... ---")

        # Ch·∫°y l·ªánh h·ªá th·ªëng ƒë·ªÉ l·∫•y b·∫£ng ARP
        with os.popen('arp -a') as f:
            arp_data = f.read().lower()

        updated = False
        new_urls = []

        # Duy·ªát qua t·ª´ng camera trong c·∫•u h√¨nh
        for cam_id, info in self.camera_configs.items():
            mac_target = info['mac'].replace(':', '-').lower()
            # T√¨m IP t∆∞∆°ng ·ª©ng v·ªõi MAC trong d·ªØ li·ªáu ARP
            match = re.search(r'(\d+\.\d+\.\d+\.\d+)\s+' + mac_target, arp_data)
            
            if match:
                new_ip = match.group(1)
                if new_ip != info['ip']:
                    print(f"‚úÖ Ph√°t hi·ªán IP m·ªõi cho {cam_id}: {new_ip}")
                    info['ip'] = new_ip
                    updated = True
            
            # X√¢y d·ª±ng l·∫°i URL RTSP
            url = f"rtsp://{info['user']}:{info['pass']}@{info['ip']}:554/cam/realmonitor?channel=1&subtype=1"
            new_urls.append(url)

        if updated:
            self.camera_urls = new_urls
            print("--- üîÑ ƒê√£ c·∫≠p nh·∫≠t l·∫°i danh s√°ch camera_urls ---")

    # Trong file security_logic.py, thay th·∫ø h√†m update_camera_ip c≈©:

    def update_camera_ip(self, full_ip_input):
        """
        C·∫≠p nh·∫≠t to√†n b·ªô ƒë·ªãa ch·ªâ IP m·ªõi cho c√°c camera trong danh s√°ch urls.
        """
        # 1. Ki·ªÉm tra ƒë·ªãnh d·∫°ng IP c∆° b·∫£n (ph·∫£i c√≥ 3 d·∫•u ch·∫•m)
        if not full_ip_input or full_ip_input.count('.') != 3:
            print(f"‚ùå ƒê·ªãa ch·ªâ IP '{full_ip_input}' kh√¥ng h·ª£p l·ªá. Vui l√≤ng nh·∫≠p ƒë·∫ßy ƒë·ªß (vd: 192.168.1.176)")
            return

        print(f"--- üîÑ ƒêang c·∫≠p nh·∫≠t sang IP m·ªõi: {full_ip_input} ---")
        
        new_urls = []
        # L∆∞u √Ω: Trong logic c·ªßa b·∫°n, self.system ch√≠nh l√† self n·∫øu h√†m n·∫±m trong SecuritySystem
        for url in self.camera_urls: 
            try:
                # T√°ch chu·ªói: rtsp://user:pass@OLD_IP:554/path
                prefix, rest = url.split('@')
                ip_and_port, path = rest.split('/', 1)
                old_ip, port = ip_and_port.split(':')
                
                # Gh√©p l·∫°i v·ªõi IP m·ªõi ho√†n to√†n
                new_url = f"{prefix}@{full_ip_input}:{port}/{path}"
                new_urls.append(new_url)
            except Exception as e:
                print(f"‚ùå L·ªói x·ª≠ l√Ω URL {url}: {e}")
                new_urls.append(url)

        # C·∫≠p nh·∫≠t danh s√°ch URL v√† c·∫•u h√¨nh b·ªô nh·ªõ
        self.camera_urls = new_urls
        
        # K√≠ch ho·∫°t chuy·ªÉn ngu·ªìn ƒë·ªÉ √°p d·ª•ng ngay
        self.switch_camera()
        print(f"‚úÖ ƒê√£ c·∫≠p nh·∫≠t xong IP: {full_ip_input}")

    def change_camera_source(self):
        """Ng·∫Øt camera hi·ªán t·∫°i v√† chuy·ªÉn sang ngu·ªìn m·ªõi"""
        # Thay v√¨ self.system.switch_camera(), h√£y d√πng:
        self.switch_camera()

    def camera_loop(self):
        """V√≤ng l·∫∑p Camera ch√≠nh v·ªõi h·ªó tr·ª£ ƒë·ªïi ngu·ªìn v√† ƒë·∫ßy ƒë·ªß t√≠nh nƒÉng v·∫Ω"""
        print("--- [CAMERA] H·ªá th·ªëng camera ƒëang kh·ªüi ƒë·ªông... ---")
        
        # C·∫•u h√¨nh FFMPEG ƒë·ªÉ t·ªëi ∆∞u RTSP
        os.environ["OPENCV_FFMPEG_CAPTURE_OPTIONS"] = "rtsp_transport;tcp|timeout;5000000" 

        # Ch·ªù load model YOLO xong m·ªõi b·∫Øt ƒë·∫ßu
        while self.model_yolo is None and self.is_running:
            time.sleep(1)

        while self.is_running:
            # L·∫•y URL hi·ªán t·∫°i theo index (Ph·∫£i ƒë·∫£m b·∫£o ƒë√£ khai b√°o trong __init__)
            rtsp_url = self.camera_urls[self.current_camera_index]
            self.cap = cv2.VideoCapture(rtsp_url, cv2.CAP_FFMPEG)
            self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
            
            if not self.cap.isOpened():
                print(f"‚ùå Kh√¥ng th·ªÉ m·ªü: {rtsp_url}. Th·ª≠ l·∫°i sau 2s...")
                time.sleep(2)
                continue
            
            print(f"‚úÖ ƒê√£ k·∫øt n·ªëi v·ªõi Camera {self.current_camera_index}")

            while self.is_running:
                success, img = self.cap.read()
                
                if not success: 
                    print("‚ö†Ô∏è ƒêang k·∫øt n·ªëi l·∫°i ho·∫∑c chuy·ªÉn camera...")
                    break # Tho√°t v√≤ng l·∫∑p con ƒë·ªÉ v√≤ng l·∫∑p cha kh·ªüi t·∫°o l·∫°i cap

                # --- B·∫ÆT ƒê·∫¶U X·ª¨ L√ù AI ---
                results = self.model_yolo.track(img, persist=True, verbose=False, classes=[0])
                
                if results and results[0].boxes:
                    keypoints_all = results[0].keypoints.data.cpu().numpy() if results[0].keypoints else []
                    
                    for i, box in enumerate(results[0].boxes):
                        track_id = int(box.id[0]) if box.id is not None else -1
                        x1, y1, x2, y2 = map(int, box.xyxy[0])
                        center = (int((x1+x2)/2), int((y1+y2)/2))

                        person_name = self.verified_tracks.get(track_id, "Dang xac minh...")
                        if track_id not in self.verified_tracks:
                            for face in self.shared_faces:
                                if self.check_overlap([x1, y1, x2, y2], face['box']):
                                    person_name = face['name']
                                    self.verified_tracks[track_id] = person_name
                                    break
                        
                        is_family = (person_name != "Unknown" and person_name != "Dang xac minh...")
                        kpts = keypoints_all[i] if len(keypoints_all) > i else None
                        action_text, action_color = self.analyze_pose_action(kpts, [x1, y1, x2, y2])

                        in_zone = self.check_danger_zone(center, DANGER_ZONE)
                        box_color = (0, 255, 0)
                        info_text = f"ID:{track_id} | {person_name}"

                        if in_zone:
                            if not is_family:
                                box_color = (0, 0, 255)
                                info_text = f"WARNING! {person_name}"
                                threading.Thread(target=winsound.Beep, args=(2000, 200)).start()
                                if time.time() - self.last_alert_time > DELAY_BAO_DONG:
                                    self.trigger_alert(img)
                            else:
                                box_color = (255, 255, 0)

                        # V·∫Ω khung v√† th√¥ng tin AI
                        cv2.rectangle(img, (x1, y1), (x2, y2), box_color, 2)
                        cv2.putText(img, info_text, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, box_color, 2)
                        
                        if action_text != "Normal":
                            cv2.putText(img, action_text, (x1, y1-35), cv2.FONT_HERSHEY_SIMPLEX, 0.8, action_color, 3)
                        
                        if kpts is not None:
                            self.draw_skeleton(img, kpts)

                # V·∫Ω v√πng nguy hi·ªÉm (ƒê·∫ßy ƒë·ªß c·∫£ khung v√† ch·ªØ)
                cv2.rectangle(img, (DANGER_ZONE[0], DANGER_ZONE[1]), (DANGER_ZONE[2], DANGER_ZONE[3]), (0, 165, 255), 2)
                cv2.putText(img, "DANGER ZONE", (DANGER_ZONE[0], DANGER_ZONE[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 165, 255), 2)

                # C·∫≠p nh·∫≠t frame ƒë·ªÉ hi·ªÉn th·ªã l√™n Kivy
                with self.lock:
                    self.shared_frame = img.copy()
                
                time.sleep(0.01)

            # Gi·∫£i ph√≥ng t√†i nguy√™n tr∆∞·ªõc khi v√≤ng l·∫∑p cha ch·∫°y l·∫ßn ti·∫øp theo
            self.cap.release()

    # --- C√ÅC H√ÄM B·ªî TR·ª¢ (HELPER) T·ª™ FILE C≈® ---
    def trigger_alert(self, img):
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        fname = f"alert_{timestamp}.jpg"
        full_path = os.path.join(THU_MUC_BAO_DONG, fname)
        cv2.imwrite(full_path, img)
        self.last_alert_time = time.time()
        threading.Thread(target=self.push_alert_to_cloud, args=(1, fname)).start()
        print(f"üö® ƒê√É GHI NH·∫¨N C·∫¢NH B√ÅO: {fname}")

    def push_alert_to_cloud(self, count, fname):
        try:
            conn = mysql.connector.connect(**DB_CONFIG)
            cursor = conn.cursor()
            sql = "INSERT INTO intrusion_logs (count_people, image_path) VALUES (%s, %s)"
            cursor.execute(sql, (count, fname))
            conn.commit()
            cursor.close()
            conn.close()
        except Exception as e:
            print(f"L·ªói Cloud: {e}")

    def check_overlap(self, box_body, box_face):
        fx, fy, fw, fh = box_face
        xA = max(box_body[0], fx)
        yA = max(box_body[1], fy)
        xB = min(box_body[2], fx + fw)
        yB = min(box_body[3], fy + fh)
        return (max(0, xB - xA) * max(0, yB - yA)) > 0

    def check_danger_zone(self, center, zone):
        cx, cy = center
        return zone[0] < cx < zone[2] and zone[1] < cy < zone[3]

    def analyze_pose_action(self, keypoints, box):
        # ... (Copy y nguy√™n logic t·ª´ file c≈©) ...
        action = "Normal"
        color = (0, 255, 0)
        if keypoints is None or len(keypoints) == 0: return action, color
        
        l_shoulder = keypoints[5][:2]
        l_hip = keypoints[11][:2]
        
        x1, y1, x2, y2 = box
        w = x2 - x1
        h = y2 - y1
        
        # Ng√£
        if w > h * 1.2: 
            return "FALL DETECTED!", (0, 0, 255)
        if l_shoulder[1] > 0 and l_hip[1] > 0 and abs(l_shoulder[1] - l_hip[1]) < h * 0.1:
             return "FALL DETECTED!", (0, 0, 255)

        # Gi∆° tay (Hands Up)
        l_wrist = keypoints[9][:2]
        r_wrist = keypoints[10][:2]
        r_shoulder = keypoints[6][:2]
        
        if (l_wrist[1] > 0 and l_wrist[1] < l_shoulder[1]) or (r_wrist[1] > 0 and r_wrist[1] < r_shoulder[1]):
             return "HANDS UP", (0, 165, 255)
             
        return action, color

    def draw_skeleton(self, img, keypoints):
        # ... (Copy y nguy√™n logic v·∫Ω x∆∞∆°ng) ...
        connections = [(5, 7), (7, 9), (6, 8), (8, 10), (5, 6), (5, 11), (6, 12), (11, 12), (11, 13), (13, 15), (12, 14), (14, 16)]
        for pt1, pt2 in connections:
            if keypoints[pt1][2] > 0.5 and keypoints[pt2][2] > 0.5:
                cv2.line(img, (int(keypoints[pt1][0]), int(keypoints[pt1][1])), (int(keypoints[pt2][0]), int(keypoints[pt2][1])), (255, 0, 255), 2)

    def get_frame(self):
        with self.lock:
            if self.shared_frame is not None:
                return self.shared_frame.copy()
        return None
    
    def get_alert_stats(self):
        today_str = datetime.now().strftime("%Y%m%d")
        all_files = [os.path.join(THU_MUC_BAO_DONG, f) for f in os.listdir(THU_MUC_BAO_DONG) if f.endswith(".jpg")]
        todays = [f for f in all_files if today_str in f]
        todays.sort(key=os.path.getmtime, reverse=True) # M·ªõi nh·∫•t l√™n ƒë·∫ßu
        return len(todays), todays
    
    # Trong file models/security_logic.py

    def upload_new_member(self, name, frame):
        """L∆∞u ·∫£nh t·∫°m v√† g·ª≠i l√™n server ƒë·ªÉ ƒëƒÉng k√Ω ng∆∞·ªùi nh√†"""
        try:
            img_path = "temp_register.jpg"
            cv2.imwrite(img_path, frame)
            
            with open(img_path, "rb") as f:
                # S·ª≠ d·ª•ng UPLOAD_URL ƒë√£ ƒë·ªãnh nghƒ©a ·ªü ƒë·∫ßu file
                response = requests.post(f"{BASE_URL}/add_member", 
                                         data={"name": name}, 
                                         files={"image": f}, 
                                         timeout=15)
            return response.json()
        except Exception as e:
            return {"status": "error", "message": str(e)}

    def fetch_server_logs(self):
        """L·∫•y danh s√°ch log x√¢m nh·∫≠p t·ª´ server Heroku"""
        try:
            response = requests.get(f"{BASE_URL}/get_logs", timeout=10)
            if response.status_code == 200:
                return response.json()
            return []
        except:
            return []